# 七天八股速记

## 第一天 Java基础知识

### ① 接口和抽象类的区别

**接口**

1. **方法**：接口里全是抽象方法，没有普通方法 。
2. **关键字**：使用 `interface` 关键字定义 。
3. **变量**：只能定义静态常量 。
4. **子类实现**：子类必须实现接口中的所有方法 。而且一个类可以 `implements` 多个接口，实现多继承 。
5. **构造方法**：接口不能有构造方法 。

**抽象类**

1. **方法**：抽象类既可以包含抽象方法，也能有普通方法 。
2. **关键字**：使用 `abstract` 关键字修饰 。
3. **变量**：可以定义成员变量 。
4. **子类实现**：子类需要实现抽象类中的所有抽象方法 。不过 Java 中一个类只能继承一个抽象类，遵循**单继承原则** 。
5. **构造方法**：抽象类可以有构造方法 ，主要用于给子类初始化一些公共资源 。

---

### ① Java中的继承和C++有什么区别

C++中可以实现多继承，Java中只能实现单继承

---

### ① Java 中有哪些数据结构？用过 HashMap 吗，说一下 HashMap 底层实现

- 数据结构有数组、链表、栈、队列、堆、树、Map等
- HashMap在JDK1.7之前采用数组加链表的形式实现，在1.8之后使用了红黑树：通过底层数组存储对象节点，采用链地址法，把新增对象节点连接在当前地址的节点下面，且规定当链表长度大于8时，将链表转换成红黑树结构。

> 介绍下红黑树：
>
> - 红黑树是一种自平衡二叉搜索树，**（Self-Balancing Binary Search Tree, BST）**，通过在节点中引入 “颜色”（红色或黑色）这一属性，并遵循严格的颜色规则，确保树的高度始终维持在 **O(log n)** 级别（n 为节点总数），从而保证插入、删除、查找等核心操作的时间复杂度稳定为 **O(log n)**，避免了普通二叉搜索树在极端情况下（如有序插入）退化为链表、操作复杂度降至 O (n) 的问题。
>
> 二叉搜索树
>
> - 对于任意节点，其左子树中**所有节点的值**都**小于**该节点的值
> - 对于任意节点，其右子树中**所有节点的值**都**大于**该节点的值
> - 左右子树本身也必须是二叉搜索树
> - （通常约定）树中不包含值相等的节点

---

### ① Java中用的是值传递还是引用传递

值传递，无论是基本数据类型还是引用数据类型，都是值传递

---

### ① 面向过程和面向对象有什么区别？

- 面向过程是一种以过程为中心的编程思想，在处理某件事的时候，以正在进行什么为主要目标，分步骤完成目标。

- 而面向对象的思想是将事物抽象为对象，赋予其属性和方法，通过每个对象执行自己的方法来完成目标。

- 面向过程效率更高，而面向对象耦合低（易复用），扩展需求，易维护。

---

### ① final、finally、finalize的区别

1. final 用于修饰属性、类、方法，修饰的变量一旦赋值后，不能被重新赋值。被 final 修饰的实例变量必须显示指定初始值。
2. finally 用于异常处理，只能用在 try/catch 中，finally 后的代码总会被执行（当`try`块中有`return`语句时，`finally`块仍然会执行 ）。
3. finalize 是 java.lang.Object 类中的方法，每一个对象都会继承这个方法，再垃圾回收机制（GC）执行的时候会被调用，允许回收未被使用的内存垃圾。

**finally 执行顺序分析（try中有return）**

1. **`try`块中执行`return`语句**：当程序执行到`try`块中的`return`语句时，它首先会将`return`语句要返回的值暂存起来。例如，如果`return`语句返回一个变量的值，它会先获取这个变量当时的值并保存。
2. **执行`finally`块**：在暂存返回值后，程序会去执行`finally`块中的代码。这是因为`finally`块的设计目的就是无论`try`块中是否发生异常，也无论`try`块以何种方式结束（包括`return`语句），都要确保执行其中的代码。
3. **返回暂存的值**：`finally`块执行完毕后，程序会返回之前暂存的值。

---

### ① 什么是序列化？是什么反序列化？

- 序列化其实就是将对象转换为字节序列格式，使其可存储可传输。
- 反序列化就是将字节序列格式转换成对象，是序列化的补集。

---

### ① 什么是不可变类？

不可变类是指实例的属性不能被修改的类。一个不可变类的实例对象从被创建出来，它的成员变量就不能被修改。Java 平台的类库中包含许多的不可变类，比如**String、基本类型的包装类等**。不可变类比一般的更加安全。

----

### ① 为什么 Java中 String 是不可变类？

1. String 类中包含 char 数组 value、整型的 offset 和 count 三个属性，这三个属性都是 private 的，且没有提供方法修改数值，因此在初始化后无法从外部改变。
2. String 类中的这三个属性都是被 final 修饰的，无法从内部进行改变。
3. 方法区有一个特殊存储区域 String Pool，当创建 String 时，如果在 String Pool 中找到相同的字符串值，则会返回一个已存在 String 的引用而不会新建一个对象。假设 String 是可变的，则会导致其他引用这个字符串值的 String 的值发生变化。

---

### ① API 和 SPI 的区别

API 和 SPI 都是制定接口传输数据。

- API 是由实现方负责定义和实现，调用方只负责调用的 API。

- 而 SPI 是指由调用方制定的接口，这个接口由实现方针对接口进行不同的实现，再由调用方选择实现方。

  例如在 JDBC 连接数据库时，针对不同的数据库需要不同的驱动实现， JDBC 提供了驱动接口，由不同的实现方进行实现了这些不同的驱动，然后我们就可以在 JDK 中引用实这些实现了的驱动包进行使用。



---

---

## 第二天 Java并发编程

### ② 线程和进程的区别

**进程**

- 定义：操作系统进行资源分配和调度的基本单位
  - 独立的运行单元，拥有各自独立的内存空间（包括**堆、方法区**等），因此 **进程内的内存资源（如对象、变量等）无法直接共享。**
  - 可以通过其他方法实现间接资源共享，如：
    - **文件系统：**多个进程可以通过读写同一个文件来共享数据。例如，进程 A 将数据写入文件，进程 B 读取该文件获取信息。但需要注意文件锁和并发控制，避免数据不一致。
    - **网络通信：**通过 Socket、HTTP、RPC（如 RMI、Dubbo）等网络协议，进程间可以通过网络传输数据实现共享。这是分布式系统中最常用的方式。
    - **共享内存：**利用操作系统提供的共享内存机制（如 Linux 的`shm`），通过 JNI（Java Native Interface）调用本地方法实现进程间内存共享。这种方式效率高，但实现复杂，且依赖底层系统。
    - **数据库或缓存：**多个进程可以通过访问同一个数据库（如 MySQL）或分布式缓存（如 Redis）共享数据。数据库和缓存本身提供了并发控制机制，适合需要持久化或高可用的场景。
    - **消息队列：**如 ActiveMQ、RabbitMQ 等，进程间通过发送 / 接收消息间接共享数据，适合异步通信场景。
- 从属关系：允许程序的实例
- 资源共享：进程
- 上下文切换：切换速度慢
- 操纵方：操作系统

**线程**

- 定义：操作系统能够进行运算调度的最小单位
- 从属关系：进程的一个执行流
- 资源共享：线程间可以共享资源
- 上下文切换：切换相对速度快
- 操纵方：编程人员

---

### ② 线程和协程的区别？什么场景下用到协程？

1. 线程和协程的区别：

   **线程**

   - 定义：操作系统最小的执行单元
   - 从属关系：一个进程可以有多个线程
   - 同步异步：同步机制
   - 资源消耗：MB级，更大

   **协程**

   - 定义：操作系统最小的资源管理单元
   - 从属关系：一个线程可以有多个协程
   - 同步异步：异步机制
   - 资源消耗：KB级，更小

   > 在一些特定的场景下，**协程**可以提供更高效的并发编程解决方案：
   >
   > - **高并发IO密集型应用**：当应用程序需要同时处理大量IO操作（如网络请求、数据库查询等）时，使用协程可以避免线程切换的开销，提高并发处理能力。
   >
   > - **异步编程**：协程可以使异步代码的编写更加简洁和可读。通过使用协程库或语言提供的异步/await等关键字，可以编写顺序化、可读性高的异步代码，而无需显式地处理回调函数和线程切换。
   >
   > - **有限状态机**：协程可以用于实现有限状态机（FSM）的编程模型。通过使用协程来表示状态和状态转换，可以简化复杂的状态逻辑和事件处理。
   >
   > 需要注意的是，协程并非在所有情况下都是最佳选择。在某些情况下，如CPU密集型任务或需要与底层系统紧密交互的情况下，线程模型可能更为适合。在选择使用协程时，需要根据具体的应用场景和需求进行评估和权衡。
   >

2. 什么场景下用到协程

   - **高并发服务**，如秒杀系统、RPC 服务器等。
   - **爬虫开发**
   - **即时通信服务**，如聊天室、游戏服务器等。

---

### ② 怎么理解容器的线程安全与线程不安全？里面具体做了什么样的实现？

1. **线程安全**

   在拥有共享数据的多条线程并行执行的程序中，代码可以通过**同步机制**保证各个线程都可以正常且正确的执行，不会出现数据错误等意外情况，成为线程安全。

2. **线程不安全**

   不提供机制保护，出现多个线程先后更改数据造成得到**脏数据**的可能。

3. **线程安全里面具体做了什么样的实现**

   - **互斥同步**

     通过 `synchronized`关键字编译后，在同步块的前后生产 `monitorenter`和`monitorexit`两个字节码指令，需要明确的 `reference`对象进行解锁。获取 `reference`对象后当前线程可以操作代码块，当锁的持有数归 0 锁释放后，可以再被其他线程获取。

   - **非阻塞同步**

     对互斥同步的优化，对于获取锁失败的线程，将不再让其挂起，而是自旋等待一段时间，若还剩无法获取锁才将其挂起。

     - **无同步方案**

       - **可重入代码**

         不允许任何进程进行修改，在运行的任何时刻中断去执行其他代码，在合理范围内（多次重入等）继续执行。

       - **线程本地储存**

         每个线程都有一个副本，对线程所做的修改都是对副本修改，不会对其他副本造成影响。

---

### ② Java 如何实现线程安全

1. 使用 `Atomic` 类，通过 CAS 保证操作不会在执行过程中被中断

   - 使用 AtomicInteger 和 AtomicReference 等原子类：
     Java 中提供了一系列原子类，可以实现针对基本数据类型和对象引用的原子操作，避免了线程安全问题。

     ```java
     private AtomicInteger count = new AtomicInteger(0);
     
     public void increment() {
         count.incrementAndGet();
     }
     ```

     

2. 使用 `synchronized`进行加锁，`volatile`关键字用于修饰变量，确保多个线程对该变量的读写操作具有**可见性**。即，一个线程对变量的修改能立即被其他线程看到。

   需要对集合容器内部的方法进行加锁，以 map 为例，由于 hashMap 内部没有锁，所以它会导致线程不安全，而如果我们使用 hashTable，由于其中使用 `synchronized` 关键字进行了加锁，就可以保证线程安全。

   ```java
   public synchronized void synchronizedMethod() {
       // 线程安全的代码块
   }
   ```

3. 使用 `TLS`（ **Thread-Local Storage（线程本地存储）**） 避免资源竞争，提供线程的副本进行同时访问和维护。

   ThreadLocal 可以实现每个线程都拥有自己的**变量副本**，从而避免多个线程之间的数据共享问题。

   ```java
   private ThreadLocal<Integer> threadLocal = ThreadLocal.withInitial(() -> 0);
   
   public void increment() {
       int value = threadLocal.get();
       threadLocal.set(value + 1);
   }
   ```

----

### ② 并发类库提供的线程池实现有哪些？

1. `newCachedThreadPool()`

**特点**：

- **动态线程数量**：核心线程数为 0，最大线程数为`Integer.MAX_VALUE`（理论上无上限）。
- **自动回收空闲线程**：线程空闲超过 60 秒会被终止并移除。
- **任务队列**：使用`SynchronousQueue`（同步队列），不存储任务，直接提交给线程执行。
- **适用场景**：短期、轻量级任务（如临时的网络请求），任务执行时间短，且任务数量波动大。

**示例**：

```java
ExecutorService cachedPool = Executors.newCachedThreadPool();
```

2. `newFixedThreadPool(int nThreads)`

**特点**：

- **固定线程数量**：核心线程数和最大线程数均为`nThreads`，线程不会被回收（除非线程池关闭）。
- **任务队列**：使用`LinkedBlockingQueue`（无界队列），当所有线程忙碌时，新任务会排队等待。
- **适用场景**：任务数量稳定、执行时间较长的场景（如服务器后台任务），避免频繁创建 / 销毁线程的开销。

**注意**：若任务队列无限增长，可能导致 OOM（内存溢出）。

**示例**：

```java
ExecutorService fixedPool = Executors.newFixedThreadPool(5); // 固定5个线程
```

3. `newSingleThreadExecutor()`

**特点**：

- **单线程执行**：核心线程数和最大线程数均为 1，所有任务按顺序执行。
- **任务队列**：使用`LinkedBlockingQueue`（无界队列），保证任务串行化处理。
- **线程自动恢复**：若唯一的线程因异常终止，会自动创建新线程替代。
- **适用场景**：需要保证任务顺序执行的场景（如日志写入、单线程事务处理），避免并发冲突。

**示例**：

```java
ExecutorService singlePool = Executors.newSingleThreadExecutor();
```

4. `newSingleThreadScheduledExecutor()`

**特点**：

- **单线程定时任务**：基于单线程实现，支持定时或周期性执行任务。
- **核心方法**：`schedule()`（延迟执行一次）、`scheduleAtFixedRate()`（固定频率执行）等。
- **适用场景**：单线程环境下的定时任务（如定期备份、心跳检测）。

**示例**：

```java
ScheduledExecutorService singleScheduledPool = Executors.newSingleThreadScheduledExecutor();
// 延迟1秒后执行任务
singleScheduledPool.schedule(() -> System.out.println("任务执行"), 1, TimeUnit.SECONDS);
```

5. `newScheduledThreadPool(int corePoolSize)`

**特点**：

- **多线程定时任务**：核心线程数为`corePoolSize`，支持定时或周期性执行任务。
- **任务队列**：使用`DelayedWorkQueue`（延迟队列），按任务的执行时间排序。
- **适用场景**：需要多个线程处理定时任务的场景（如多任务定时调度），避免单线程瓶颈。

**示例**：

```java
ScheduledExecutorService scheduledPool = Executors.newScheduledThreadPool(3);
// 延迟2秒后，每3秒执行一次任务
scheduledPool.scheduleAtFixedRate(() -> System.out.println("周期性任务"), 2, 3, TimeUnit.SECONDS);
```

6. `newWorkStealingPool(int parallelism)`

**特点**：

- **工作窃取机制**：基于`ForkJoinPool`实现，线程可 “窃取” 其他线程的任务执行，提高 CPU 利用率。
- **并行度**：`parallelism`指定并行线程数（默认等于 CPU 核心数），无最大线程数限制。
- **任务队列**：每个线程有独立的双端队列，空闲线程从其他队列尾部窃取任务。
- **适用场景**：CPU 密集型任务（如大规模计算），充分利用多核处理器性能。

**示例**：

```java
ExecutorService workStealingPool = Executors.newWorkStealingPool(4); // 并行度为4
```

**总结对比**

| 线程池方法                           | 核心线程数 | 最大线程数          | 队列类型              | 核心特点           | 适用场景         |
| ------------------------------------ | ---------- | ------------------- | --------------------- | ------------------ | ---------------- |
| `newCachedThreadPool()`              | 0          | `Integer.MAX_VALUE` | `SynchronousQueue`    | 动态伸缩，短期任务 | 轻量、短期任务   |
| `newFixedThreadPool(n)`              | n          | n                   | `LinkedBlockingQueue` | 固定线程，任务排队 | 稳定、长期任务   |
| `newSingleThreadExecutor()`          | 1          | 1                   | `LinkedBlockingQueue` | 单线程串行执行     | 需顺序执行的任务 |
| `newSingleThreadScheduledExecutor()` | 1          | 1                   | `DelayedWorkQueue`    | 单线程定时任务     | 单线程定时调度   |
| `newScheduledThreadPool(n)`          | n          | `Integer.MAX_VALUE` | `DelayedWorkQueue`    | 多线程定时任务     | 多任务定时调度   |
| `newWorkStealingPool(n)`             | n          | 无限制              | 双端队列（每个线程）  | 工作窃取，多核高效 | CPU 密集型计算   |

实际开发中，需根据任务特性（执行时间、数量、是否定时等）选择合适的线程池，或通过`ThreadPoolExecutor`自定义线程池参数以满足更精细的需求。

---

### ② 线程池中的几个参数，比如核心线程数、最大线程数、如果让你定，你会怎么样去设定这些值？

一般多线程执行的任务类型可以分为 **CPU密集型**和**I/O密集型**，根据不同的任务类型，我们计算线程数的方法也不一样。

假设 N 为CPU核心数，WT 为线程等待时间，ST 为线程时间运行时间

- **CPU 密集型任务：**主要消耗CPU资源，可以额外设置一个线程，一旦任务暂停，CPU就会处于空闲状态，额外的线程可以充分利用 CPU 的空闲时间，**线程数为 N + 1**

- **I/O 密集型任务：**I/O 交互的处理消耗较大，而线程在处理 I/O 的时候不会占用 CPU 来处理，因此可以多配置一些线程，**线程数 2*N**

- 在一般的业务应用场景中，我们可以用下列公式计算线程数：

  **线程数 = N * （1 + WT / ST）**

可以根据实际业务场景，从  “N+1” 和 “2N” 中选出一个适合的，计算出一个大概的线程数，之后通过实际压测进行增大或减小线程数调整，然后观察具体的运行时间变化，最终确定一个具体的线程数。

---

### ② Java 中有哪些锁

![image-20250909180055005](https://typora-yuanbaoer2.oss-cn-shanghai.aliyuncs.com/img-typora/image-20250909180055005.png)

---

### ② 怎么理解乐观锁和悲观锁？

**乐观锁：**在操作数据时非常的乐观，**认为别人不会修改数据**，因此不加锁，在执行数据更新时采用比较判断的方式进行操作，如果当前数据被修改过，则放弃操作，否则就执行操作。**乐观锁默认不会上锁**

典型的乐观锁包括 **CAS 机制**和**版本号机制**

- **CAS 机制（Compare And Swap，比较并交换）**操作过程包括 compare 和 set，通过内存位置、预期值和拟写入的新值三个数据，先去比较待修改对象是否为它自身所持有的对象，然后比较该对象的数据是否等于预期数据，如果都为是，那就将该对象数据修改为新的数据。

  > CAS（Compare And Swap，比较并交换）是一种**无锁同步机制**，用于多线程环境下实现变量的原子操作，避免了使用锁（如`synchronized`）带来的性能开销和线程阻塞问题。它是并发编程中的核心技术，Java 中的`java.util.concurrent.atomic`包（如`AtomicInteger`）就是基于 CAS 实现的。
  >
  > ### **CAS 的核心原理**
  >
  > CAS 操作涉及三个关键值：
  >
  > 1. **内存地址 V**：存储要修改的变量的内存位置。
  > 2. **预期值 A**：线程认为变量当前应该的值。
  > 3. **新值 B**：线程想要将变量修改为的值。
  >
  > **执行逻辑**：
  > 当且仅当内存地址 V 中的值等于预期值 A 时，才将 V 的值更新为新值 B；否则不做任何操作。整个过程是**原子操作**（由 CPU 指令保证，不可中断）。
  >
  > 可以简单理解为以下伪代码：
  >
  > ```java
  > boolean cas(V, A, B) {
  >     if (V的值 == A) {
  >         V的值 = B;
  >         return true; // 修改成功
  >     } else {
  >         return false; // 修改失败
  >     }
  > }
  > ```
  >
  > ### **CAS 的优势：无锁编程**
  >
  > 与`synchronized`等锁机制相比，CAS 的核心优势是**非阻塞**：
  >
  > - 当多个线程竞争时，失败的线程不会被挂起（阻塞），而是可以选择重试或放弃，减少了线程上下文切换的开销。
  > - 适用于**读多写少**的场景，性能优于锁机制。
  >
  > ### **Java 中的 CAS 应用：`AtomicInteger`**
  >
  > Java 通过`sun.misc.Unsafe`类直接调用 CPU 的 CAS 指令实现原子操作。以`AtomicInteger`的`incrementAndGet()`（自增 1）为例：
  >
  > ```java
  > public class AtomicInteger extends Number implements java.io.Serializable {
  >     private volatile int value; // 共享变量，volatile保证可见性
  > 
  >     public final int incrementAndGet() {
  >         return unsafe.getAndAddInt(this, valueOffset, 1) + 1;
  >     }
  > }
  > 
  > // Unsafe类中的核心实现（简化）
  > public final int getAndAddInt(Object o, long offset, int delta) {
  >     int expected;
  >     do {
  >         expected = this.getIntVolatile(o, offset); // 读取当前值（预期值A）
  >     } while (!this.compareAndSwapInt(o, offset, expected, expected + delta)); 
  >     // 循环重试：若CAS失败（预期值与实际值不符），重新读取预期值并再次尝试
  >     return expected;
  > }
  > ```
  >
  > **执行流程**：
  >
  > 1. 线程读取当前值作为预期值 A。
  > 2. 调用`compareAndSwapInt`执行 CAS 操作，尝试将值更新为 A+1。
  > 3. 若成功，返回新值；若失败（其他线程已修改值），重新读取预期值并重试（**自旋**），直到成功。
  >
  > ### **CAS 的问题与局限性**
  >
  > 1. **ABA 问题**
  >    - 场景：线程 1 读取值为 A，线程 2 将 A 改为 B，再改回 A。线程 1 的 CAS 操作会认为值未变而成功，但实际发生了中间修改。
  >    - 解决：使用 “版本号” 机制（如`AtomicStampedReference`），每次修改时更新版本号，CAS 时同时检查值和版本号。
  > 2. **自旋开销**
  >    - 若并发激烈，CAS 可能多次失败并持续自旋，占用 CPU 资源（类似于 “忙等”）。
  >    - 优化：JDK 中的一些实现会限制自旋次数（如`Synchronized`的锁升级机制）。
  > 3. **只能保证单个变量的原子操作**
  >    - CAS 仅支持对单个变量的原子修改，无法直接实现多个变量的原子操作（需用锁或组合对象）。
  >
  > ### **总结**
  >
  > CAS 是一种高效的无锁同步机制，通过 “比较 - 交换” 的原子操作保证变量修改的线程安全，避免了锁的阻塞开销。它是 Java 并发工具类（如`Atomic*`、`ConcurrentHashMap`）的核心实现原理，适用于并发量不极端、读多写少的场景。但需注意 ABA 问题、自旋开销等局限性，根据实际场景选择合适的同步方案。

- **版本号机制：**在表中增加一个 version 字段，每更新一次数据就将此值+1。当读取数据时，连同version字段一起读取。当提交更新时，会将数据库表中对应记录的当前版本号与之前取出来的版本号比较，如果一致则执行更新，如果不一致则表示是过期数据放弃操作。

**悲观锁：**在操作数据时非常悲观，**总是认为别人会修改数据**，因此需要加锁，在更新数据时直到操作执行完毕才释放资源。**悲观锁默认直接上锁。**

典型的悲观锁实现方式为：`synchronized`关键字、`ReentrantLock`独立锁和 MySQL中的排他锁

- `synchronized`关键字在多线程访问共享数据时同一时刻只能由单个线程抢到资源去执行。且在线程切换时，涉及到操作系统内核态和用户态的切换，这些操作会消耗额外的资源，**因此效率较低。**

---

### ② 怎么理解自旋锁？为什么还会有自旋锁？

- **自旋锁：**线程的阻塞和唤醒需要 CPU 从用户态转为核心态，频繁的阻塞和唤醒对 CPU 来说负担较大，会给系统的并发性能带来很大的压力。 且对象锁的锁状态的持续时间很短，为了这一段很短的时间频繁地阻塞和唤醒线程是非常不值得的，因此引入了自旋锁。

  - 自旋锁让该线程等待一段时间，不会被立即挂起，看持有锁的线程是否会很快释放锁。
    为了达成这个等待，自旋锁会执行一段无意义的循环，这个过程称为自旋。
    自旋等待不能替代阻塞，虽然自旋可以避免线程切换带来的开销，但是却占用了处理器的时间。 如果持有锁的线程很快就释放了锁，那么自旋的价值就非常高。否则，自旋的线程就会白白占用处理的资源，不会做任何有意义的工作，反而浪费了性能。 因此，自旋必须要有一个限度，如果自旋超过了设定的时长仍然没有获取到锁，则需要被挂起。

    自旋锁在 JDK 1.4.2 中引入，默认关闭，可以使用 -XX:+UseSpinning 开启，在 JDK1.6 中改为默认开启。同时自旋的默认次数为 10 次，可以通过修改参数 -XX:PreBlockSpin 来调整。
    但是通过调整 -XX:preBlockSpin 来调整自旋次数，会导致很多意外情况。比如刚退出线程锁就被释放。因此 JDK1.6 引入了自适应的自旋锁。

  > 自旋锁（Spin Lock）是一种**非阻塞同步机制**，其核心思想是：当线程尝试获取锁失败时，不会立即阻塞（放弃 CPU 资源），而是通过**循环不断尝试获取锁**（“自旋”），直到成功获取或达到一定次数后再阻塞。
  >
  > ### **为什么需要自旋锁？**
  >
  > 自旋锁的设计源于对**短期锁竞争场景**的优化。传统的互斥锁（如`synchronized`）在获取锁失败时，会将线程切换到阻塞状态（进入内核态等待），这涉及**线程上下文切换**（保存 / 恢复线程状态）和**内核态与用户态切换**，开销较大（通常是微秒级）。
  >
  > 而在以下场景中，锁被占用的时间极短（如纳秒级）：
  >
  > - 锁保护的临界区代码执行时间很短（如简单的变量修改）。
  > - 并发冲突概率低，线程等待锁的时间远小于上下文切换的时间。
  >
  > 此时，让线程 “自旋等待”（循环尝试获取锁）比 “阻塞等待” 更高效 —— 省去了上下文切换的开销，提升整体性能。
  >
  > ### **自旋锁的工作原理**
  >
  > 1. 线程 A 获取锁成功，执行临界区代码。
  > 2. 线程 B 尝试获取锁，发现锁已被占用，进入自旋状态（循环检查锁是否释放）。
  > 3. 线程 A 释放锁后，线程 B 在自旋过程中检测到锁可用，立即获取锁并执行。
  >
  > 伪代码示意：
  >
  > ```java
  > public class SpinLock {
  >     private AtomicReference<Thread> owner = new AtomicReference<>();
  > 
  >     // 获取锁：自旋直到成功
  >     public void lock() {
  >         Thread current = Thread.currentThread();
  >         // 循环尝试CAS操作，直到成功获取锁
  >         while (!owner.compareAndSet(null, current)) {
  >             // 空循环（自旋），不断重试
  >         }
  >     }
  > 
  >     // 释放锁
  >     public void unlock() {
  >         Thread current = Thread.currentThread();
  >         // 只有持有锁的线程才能释放
  >         owner.compareAndSet(current, null);
  >     }
  > }
  > ```
  >
  > - 核心依赖 CAS 操作：通过`AtomicReference`的`compareAndSet`实现锁的获取与释放，保证原子性。
  > - 自旋过程中，线程始终处于**运行状态**（不放弃 CPU），持续占用处理器资源。
  >
  > ### **自旋锁的适用场景与局限性**
  >
  > #### **适用场景**：
  >
  > 1. **短期锁持有**：临界区代码执行时间极短（如几纳秒），自旋等待时间远小于上下文切换时间。
  > 2. **低并发冲突**：锁竞争不激烈，线程自旋几次就能获取到锁。
  > 3. **多核处理器**：自旋时不会阻塞其他线程（其他核可正常工作），适合多核环境。
  >
  > #### **局限性**：
  >
  > 1. **CPU 资源浪费**：若锁被长期占用（如毫秒级），自旋线程会持续消耗 CPU 资源（“空转”），导致系统性能下降。
  > 2. **不公平性**：自旋锁无法保证等待线程的获取顺序，可能导致某些线程长期自旋（“饥饿”）。
  > 3. **不适合单核处理器**：单核 CPU 上，自旋线程会占用全部 CPU 时间，导致持有锁的线程无法执行，形成死锁。
  >
  > ### **Java 中的自旋锁应用**
  >
  > Java 并未直接提供自旋锁 API，但许多并发组件内部使用了自旋优化：
  >
  > - **`synchronized`锁**：JDK 6 及以上对`synchronized`进行了优化，引入 “偏向锁→轻量级锁→重量级锁” 的升级机制，其中**轻量级锁阶段会使用自旋**（默认 10 次），避免直接升级为重量级锁（阻塞）。
  > - **`ReentrantLock`**：基于 AQS（AbstractQueuedSynchronizer）实现，默认使用 “非公平锁”，获取锁失败时会先自旋尝试，再进入等待队列。
  >
  > ### **总结**
  >
  > 自旋锁是对 “短期锁竞争” 场景的针对性优化，通过 “忙等” 避免线程阻塞的上下文切换开销，提升高并发下的性能。但它的适用范围有限，仅适合锁持有时间短、冲突少的场景，否则会因 CPU 空转而降低效率。
  >
  > 简单来说：**自旋锁用 “时间换空间”（CPU 资源换上下文切换开销），是对传统阻塞锁的有效补充**。

- **适应自旋锁**

  自适应自旋锁的自旋的次数不再是固定的，它由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。

  线程如果自旋成功了，那么下次自旋的次数会更多，因为虚拟机认为既然上次成功了，那么此次自旋也很有可能会再次成功，那么它就会允许自旋等待持续的次数更多。反之，如果对于某个锁，很少有自旋能够成功的，那么在以后要或者这个锁的时候自旋的次数会减少甚至省略掉自旋过程，以免浪费处理器资源。


---

### ② 间隙锁是什么

间隙是对于键值在条件范围内但并不存在的记录。

间隙锁是指在索引数据时，使用的是范围条件而不是相等条件，并请求共享或排他锁时，InnoDB 会给符合条件的已有数据记录的索引项进行加锁。

间隙锁是开区间，间隙锁 + 行锁合称 next-key lock，每个 next-key lock 是左开右闭区间。间隙锁和 next-key lock 的引入可以解决幻读问题。

> 间隙锁（Gap Lock）是 MySQL 中 InnoDB 存储引擎在**Repeatable Read（可重复读）隔离级别**下，为解决**幻读问题**而引入的一种行级锁。它锁定的不是具体的记录，而是**索引记录之间的间隙**，防止其他事务在该间隙中插入新数据，从而保证事务的隔离性和数据一致性。
>
> ### **核心作用：阻止间隙插入，解决幻读**
>
> 幻读是指一个事务在两次查询中，由于其他事务插入了新数据，导致后一次查询出现了前一次查询没有的 “新记录”。例如：
>
> 1. 事务 A 查询`id > 10`的记录（假设当前只有`id=11`的记录）。
> 2. 事务 B 插入`id=12`的新记录并提交。
> 3. 事务 A 再次查询`id > 10`，会出现`id=12`的新记录，即 “幻读”。
>
> 间隙锁通过锁定`id=11`之后的间隙，阻止事务 B 插入`id=12`的记录，从而避免幻读。
>
> ### **间隙的定义**
>
> 间隙是指索引中**两个连续记录之间的区间**，或**第一条记录之前的区间**、**最后一条记录之后的区间**。例如，对于索引值为`(5, 10, 15)`的表，存在以下间隙：
>
> - `(-∞, 5)`：小于 5 的区间
> - `(5, 10)`：5 到 10 之间的区间
> - `(10, 15)`：10 到 15 之间的区间
> - `(15, +∞)`：大于 15 的区间
>
> ### **间隙锁的触发场景**
>
> 当 InnoDB 在**可重复读隔离级别**下，使用**范围查询**或**等值查询未命中记录**时，会自动加间隙锁。例如：
>
> ```sql
> -- 表结构：id为主键，存在记录id=10、20
> CREATE TABLE test (id INT PRIMARY KEY, name VARCHAR(10));
> INSERT INTO test VALUES (10, 'a'), (20, 'b');
> ```
>
> 1. **范围查询**：
>
>    ```sql
>    -- 事务A执行：查询id在10到20之间的记录
>    SELECT * FROM test WHERE id BETWEEN 10 AND 20 FOR UPDATE;
>    ```
>
>    - 此时会锁定`id=10`和`id=20`的记录（行锁），同时锁定`(10, 20)`的间隙（间隙锁）。
>    - 其他事务无法在`(10, 20)`中间插入`id=15`的新记录。
>
> 2. **等值查询未命中**：
>
>    ```sql
>    -- 事务A查询id=15的记录（不存在）
>    SELECT * FROM test WHERE id = 15 FOR UPDATE;
>    ```
>
>    - 虽然没有匹配的记录，但会锁定`(10, 20)`的间隙，阻止其他事务插入`id=15`的记录。
>
> ### **特点与注意事项**
>
> 1. **仅在可重复读隔离级别生效**：其他隔离级别（如 Read Committed）不会使用间隙锁（MySQL 默认在 Read Committed 下关闭间隙锁）。
> 2. **不阻塞读操作**：间隙锁仅阻止插入、更新、删除等写操作，不影响其他事务的读操作。
> 3. **可能导致死锁**：多个事务锁定重叠间隙时，可能因互相等待对方释放锁而产生死锁。例如：
>    - 事务 A 锁定`(5, 10)`间隙。
>    - 事务 B 锁定`(8, 15)`间隙。
>    - 两者都尝试插入`id=9`的记录，会因互相等待对方释放重叠的`(8, 10)`间隙而死锁。
> 4. **与行锁结合形成 next-key 锁**：InnoDB 中，行锁 + 间隙锁的组合称为`next-key锁`，它既锁定记录本身，也锁定记录前面的间隙（例如`id=10`的 next-key 锁会锁定`(5, 10]`区间）。
>
> ### **总结**
>
> 间隙锁是 InnoDB 在可重复读隔离级别下解决幻读的核心机制，通过锁定索引间隙防止新数据插入。它保证了事务隔离性，但也可能因锁范围扩大导致性能下降或死锁，实际使用中需根据业务场景合理设计索引和查询语句。

---

---

## 第三天 计算机网络

### ③ 讲一讲对 TCP/IP 模型的认识

TCP/IP 模型将复杂的网络通信过程拆解为**四层功能独立的模块**，每层仅与相邻层交互（“上层调用下层服务，下层为上层提供支持”），这种 “分层思想” 降低了技术复杂度，也方便不同厂商的设备兼容（只要遵守同一层的协议，即可互通）。

四层结构从下到上依次为：**网络接口层、网际层（IP 层）、传输层、应用层**，各层的功能、核心协议及作用如下表所示：

| 层级（从下到上）            | 核心功能                                                     | 核心协议 / 技术                                              | 通俗理解                                                     |
| --------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **1. 网络接口层**（链路层） | 负责 “物理介质上的信号传输”，将上层的 “数据包” 转换为电信号 / 光信号，或反之 | Ethernet（以太网）、Wi-Fi（802.11 协议）、PPP（拨号协议）、MAC 地址 | 相当于 “快递的运输工具”（如货车、飞机），处理 “最后一公里” 的物理传输 |
| **2. 网际层（IP 层）**      | 负责 “跨网络的路由选择”，确定数据包从 “源设备” 到 “目标设备” 的路径，实现 “端到端的地址定位” | IP（IPv4/IPv6）、ICMP（网络控制报文协议，如 ping 命令）、ARP（地址解析，将 IP 转 MAC） | 相当于 “快递的路由系统”（如快递分拣中心），根据 “收件人地址（IP）” 规划运输路径 |
| **3. 传输层**               | 负责 “端到端的可靠通信”，处理数据的 “完整性、顺序性”，并区分同一设备上的不同应用 | TCP（传输控制协议）、UDP（用户数据报协议）、端口号           | 相当于 “快递的配送员”，不仅要把包裹送对地址，还要确保包裹没丢、没乱序，且能区分是 “家庭收件” 还是 “公司收件”（端口号对应应用） |
| **4. 应用层**               | 直接为用户应用提供 “具体的通信服务”，定义应用间的数据交互格式和规则 | HTTP/HTTPS（网页浏览）、FTP（文件传输）、SMTP（邮件发送）、DNS（域名解析）、SSH（远程登录） | 相当于 “快递的具体业务类型”（如文件快递、生鲜快递），满足不同场景的通信需求 |

TCP/IP 模型的核心是 “协议”—— 协议是不同设备间的 “通信语言”，以下是各层最关键的协议及其特点：

**1. 网际层：IP 协议（网际协议）**

IP 协议是 TCP/IP 模型的 “灵魂”，负责 “地址定位” 和 “跨网络传输”，核心特点：

- **无连接**：发送数据包前不与目标设备建立 “连接”，直接发送，无法保证数据包一定到达。
- **不可靠**：不保证数据包的顺序（可能乱序）、完整性（可能丢失或损坏），也不重传丢失的数据包。
- **两种版本**：
  - IPv4：32 位地址（如`192.168.1.1`），地址资源有限，已接近耗尽。
  - IPv6：128 位地址（如`2001:0db8:85a3:0000:0000:8a2e:0370:7334`），地址充足，是未来互联网的主流。

**2. 传输层：TCP 与 UDP（核心区别）**

传输层的核心是 “保障数据传输的可靠性” 或 “追求传输速度”，因此分为两种协议：

| 对比维度     | TCP（传输控制协议）                                          | UDP（用户数据报协议）                                        |
| ------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **连接方式** | 面向连接（需 “三次握手” 建立连接，“四次挥手” 断开连接）      | 无连接（直接发送数据，无需建立连接）                         |
| **可靠性**   | 可靠（保证数据不丢失、不重复、按顺序到达）                   | 不可靠（数据可能丢失、乱序，不重传）                         |
| **速度**     | 较慢（需处理确认、重传等机制）                               | 较快（无额外机制，开销小）                                   |
| **适用场景** | 对可靠性要求高的场景：网页浏览（HTTP/HTTPS）、文件传输（FTP）、邮件（SMTP）、即时通信（微信文字） | 对速度要求高、可容忍少量丢失的场景：视频直播、语音通话（VoIP）、游戏（王者荣耀）、DNS 解析 |

**3. 应用层：常见协议的作用**

应用层协议直接对应用户的使用场景，例如：

- **HTTP/HTTPS**：HTTP 是 “超文本传输协议”，用于浏览器加载网页；HTTPS 是 HTTP 的加密版本（基于 SSL/TLS），保障数据传输安全（如网购、网银）。
- **DNS**：“域名系统”，将易记的域名（如`www.baidu.com`）转换为 IP 地址（如`180.101.49.11`）—— 相当于 “互联网的通讯录”。
- **FTP**：“文件传输协议”，用于在设备间传输大文件（如服务器上传 / 下载文件）。

#### TCP/IP 模型与 OSI 参考模型的区别

常有人将 TCP/IP 模型与 OSI 参考模型（国际标准化组织制定的 7 层模型）对比，两者的核心区别在于 “分层数量” 和 “实用性”：

| 对比维度     | TCP/IP 模型（四层）                                          | OSI 参考模型（七层）                                       |
| ------------ | ------------------------------------------------------------ | ---------------------------------------------------------- |
| **分层结构** | 应用层、传输层、网际层、网络接口层                           | 应用层、表示层、会话层、传输层、网络层、数据链路层、物理层 |
| **核心特点** | 实用导向（源于实践，简化分层，已大规模应用）                 | 理论导向（追求全面，分层细致，但过于复杂，未大规模落地）   |
| **对应关系** | 应用层 = OSI 的应用层 + 表示层 + 会话层；网络接口层 = OSI 的数据链路层 + 物理层 | -                                                          |

#### TCP/IP 模型的意义与局限

1. **核心意义**

- **互联互通的基础**：全球所有互联网设备（电脑、手机、服务器、路由器）都遵守 TCP/IP 协议，实现了 “跨厂商、跨网络、跨地域” 的通信。
- **技术简化与兼容**：分层思想降低了网络开发的复杂度（如开发浏览器只需关注应用层 HTTP，无需关心物理层的信号传输），同时方便不同厂商的设备兼容。

2. **主要局限**

- **安全性不足**：早期 TCP/IP 协议设计时未考虑安全（如 IP 协议不加密，TCP 协议的 “三次握手” 可能被攻击（SYN 洪水攻击）），需依赖上层协议（如 HTTPS、SSL/TLS）或额外技术（如防火墙）弥补。
- **IPv4 地址耗尽**：IPv4 仅 32 位地址，全球可用地址已不足，虽通过 NAT（网络地址转换，如家庭路由器共享一个公网 IP）缓解，但长期需依赖 IPv6 过渡。

#### 总结

TCP/IP 模型是互联网的 “骨架”，通过四层结构和核心协议，将复杂的网络通信拆解为可实现、可兼容的模块。理解 TCP/IP 模型，不仅能明白 “上网的本质”，也是学习网络编程（如 Socket 编程）、网络运维（如排查网络故障）、网络安全的基础。

---

### ③ TCP 和 UDP 的区别

|              |                    UDP                     |                  TCP                   |      |
| :----------- | :----------------------------------------: | :------------------------------------: | ---- |
| 是否连接     |                   无连接                   |                面向连接                |      |
| 是否可靠     |    不可靠传输，不使用流量控制盒拥塞控制    |    可靠传输，使用流量控制和拥塞传输    |      |
| 传输速度     |                     快                     |                   慢                   |      |
| 连接对象个数 | 支持一对一、一对多、多对一和多对多交互通信 |            只能是一对一通信            |      |
| 传输方式     |                  面向报文                  |               面向字节流               |      |
| 首部开销     |            首部开销小，仅8字节             |       首部最小20字节，最大60字节       |      |
| 适用场景     |   适用于实时应用（游戏、视频会议、直播）   | 适用于要求可靠传输的应用，例如文件传输 |      |

---

### ③ TCP 保证可靠性的方式

1. **检验和**：就像快递单上的防伪码，收件人收到包裹后扫码核对，确认包裹在运输中没有被私自拆改或损坏。如果核对失败，就会拒收这个包裹。
2. **序列号**：相当于给每个包裹编上顺序号（如 1 号、2 号、3 号）。即使快递中途绕路导致顺序混乱，收件人也能按编号重新整理，不会弄错内容顺序，也能发现是否有包裹丢失。
3. **确认应答**：类似收件人收到包裹后给寄件人发 "已收到" 的短信。比如收到 1-10 号包裹，就回复 "已收到 10 号及之前的所有包裹"，寄件人知道后就会继续发 11 号及以后的。
4. **超时重传**：如果寄件人发了包裹后，过了很久没收到确认短信（超时），就会认为包裹可能丢了，自动重新发送这个包裹。
5. **连接管理（三次握手 / 四次挥手）**：
   - 三次握手：像打电话时的 "喂，你在吗？"" 我在，你能听到吗？""能听到，开始说吧"，确认双方都能正常收发信息后才开始传递数据。
   - 四次挥手：类似挂电话前的 "我说完了"" 好的，我知道了，我再确认下有没有遗漏 ""确认完毕，没问题"" 那挂了啊 "，确保双方都处理完数据再断开连接。
6. **流量控制**：就像收件人告诉寄件人 "我这里暂时放不下太多包裹，你慢点寄"，避免收件人因处理不过来而丢失数据（通过滑动窗口机制实现）。
7. **拥塞控制**：类似寄件人发现最近快递网点总是爆仓（网络拥堵），就主动放慢发货速度，等物流顺畅了再恢复正常，避免越堵越乱导致更多包裹丢失。

---

### ③ HTTP 常用的请求方式

| 请求方式 | 英文全称 | 主要作用                                                     | 特点与注意事项                                               |
| -------- | -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| GET      | Get      | 从服务器**获取资源**（如网页、图片、数据等）                 | 1. 请求参数附加在 URL 后，可见且长度有限制 2. 仅用于获取数据，不修改服务器状态 3. 可被缓存、收藏、历史记录保存 |
| POST     | Post     | 向服务器**提交数据**，通常用于创建新资源（如表单提交、上传文件） | 1. 请求参数放在请求体中，不可见且长度无限制 2. 会修改服务器状态（如新增数据） 3. 不可缓存，不会被收藏 |
| PUT      | Put      | 向服务器**提交数据**，用于**完整更新**已有资源（如修改用户信息、替换文件） | 1. 若资源不存在，可能会创建新资源 2. 要求提供资源的完整数据（覆盖式更新） 3. 幂等操作（多次执行结果一致） |
| DELETE   | Delete   | 请求服务器删除指定资源（如删除一条记录、一个文件）           | 1. 幂等操作（多次删除同一资源结果一致） 2. 实际应用中可能仅标记删除，而非物理删除 |
| PATCH    | Patch    | 对资源进行**部分更新**（如仅修改用户的邮箱地址，无需提交完整信息） | 1. 与 PUT 的区别：仅需提供需要修改的部分数据 2. 非幂等（多次执行可能导致不同结果，需谨慎设计） |
| HEAD     | Head     | 与 GET 类似，但仅返回响应头，不返回响应体                    | 1. 用于获取资源的元信息（如文件大小、修改时间） 2. 可用于检查资源是否存在、是否更新 |
| OPTIONS  | Options  | 询问服务器支持的请求方式、跨域权限等信息                     | 常用于跨域请求前的 “预检请求”，确认服务器是否允许后续操作 帮助客户端了解服务器的能力范围 |

---

### ③ HTTP 和 HTTPS 有什么区别？HTTPS 是如何保证传输安全的

1. **HTTP 和 HTTPS的区别：**

| 对比维度         | HTTP (超文本传输协议)                 | HTTPS (超文本传输安全协议)                        | 通俗理解类比                                                 |
| ---------------- | ------------------------------------- | ------------------------------------------------- | ------------------------------------------------------------ |
| **安全属性**     | 明文传输，无加密                      | 加密传输，数据不可被窃取 / 篡改                   | 平信内容可被偷看、涂改；挂号信内容被密封且加密，只有收件人能拆 |
| **核心协议组成** | 仅 HTTP 协议                          | HTTP + SSL/TLS 协议（加密层）                     | 平信只有信纸；挂号信 = 信纸 + 加密信封 + 防伪标签            |
| **端口号**       | 默认使用 80 端口                      | 默认使用 443 端口                                 | 不同类型的信件走不同的邮局窗口                               |
| **证书要求**     | 无需任何证书                          | 必须配备 CA 机构（第三方权威机构）颁发的 SSL 证书 | 平信不用盖章；挂号信需要邮局的官方防伪章，证明不是伪造的     |
| **性能**         | 传输速度快（无加密 / 解密步骤）       | 速度略慢（多了加密 / 解密、证书验证环节）         | 平信直接投递；挂号信要核对身份、验证防伪，步骤更多           |
| **地址标识**     | 网址以`http://`开头，浏览器无 “锁” 标 | 网址以`https://`开头，浏览器显示 “锁” 标          | 平信信封无特殊标记；挂号信信封有明显防伪标识                 |

2. **HTTPS 的安全性保证**

   HTTPS 是在 HTTP的基础上增加了 **SSL/TLS 协议**

   在传输数据时，首先服务端会先将自己的公钥拿给第三方的 CA 机构，CA 会用自己的私钥对服务端的公钥签名，生成证书。服务端将 CA 签名的证书发送给浏览器，浏览器通过内嵌的 CA 机构的公钥对证书解密，得到服务端的公钥，这一过程采用非对称加密的方式。
   然后浏览器会随机生成一个密码信息，通过解密得到的服务端公钥对这个随机密钥进行加密，然后发送给服务端，服务端通过自己的私钥可以解密这个密文，从而拿到浏览器随机生成的密钥。
   最后浏览器个服务器双方通过这个密钥，对需要发送的数据进行对称加密。由此便保证了数据传输的安全性。

   由于非对称加密的安全性更高，所以采用非对称加密的方式对密钥进行加密；但是在传输数据时，由于非对称加密的效率较低，所以采用对称加密的方式对数据进行加密。


---

### ③ TCP 中有一个 TIME_WAIT 状态解释一下

`TIME_WAIT`是 TCP 连接 “四次挥手”（关闭连接）过程中，**主动关闭连接的一方**会进入的状态。

在这个状态下，主动方会保持一个 2MSL 的等待时间后才断开连接回到起始 CLOSED 状态。其中的 MSL 是 Maximum Segment Lifetime，最大报文生存寿命，指一个数据包在网络中的最大生存时间。之前要保持 2MSL 的等待时间，有以下两方面原因：

#### 1. 确保被动关闭方收到最终的`ACK`（防止连接 “关不干净”）

TCP 是 “可靠传输”，所有报文都需要确认。在四次挥手的第 4 步，主动关闭方发送的 `ACK` 报文，可能因为网络延迟、丢包等原因，没被被动关闭方收到。

- 如果主动方不等直接关连接：被动关闭方会因为没收到 `ACK`，不断重发 `FIN` 报文，但此时主动方已释放资源，无法回应，被动方会一直卡在 `LAST_ACK` 状态，连接 “僵死”；
- 有了`TIME_WAIT`：主动方会等 2*MSL—— 足够被动方重发几次 `FIN`（MSL 是报文在网络中能存活的最长时间，2*MSL 意味着 “即使第一次`ACK`丢了，被动方重发的`FIN`也能在 2*MSL 内传到主动方，主动方再补发`ACK`”），确保被动方收到最终确认，双方都能正常关连接。

**通俗类比**：你跟朋友打电话说 “我挂了啊”（发`FIN`），朋友回 “好”（发`ACK`），你又说 “那我真挂了”（发最终`ACK`）。但你怕朋友没听到最后一句，会等几秒 —— 如果朋友再问 “喂？还在吗？”（重发`FIN`），你就再回答一次 “真挂了”（补`ACK`）；如果没声音，就确认朋友听到了，再挂电话。

#### 2. 避免 “旧连接的残留报文” 干扰 “新连接”（防止数据混乱）

TCP 连接的唯一标识是 “源 IP + 源端口 + 目的 IP + 目的端口”（四元组）。如果主动方刚关闭连接就立刻用相同四元组建立新连接，网络中可能还残留着上一次连接的 “旧报文”（比如因网络拥堵延迟的数据包）。

- 这些旧报文会被新连接误接收，导致新连接的数据混乱（比如上一次的 “取消订单” 报文，被新连接当成 “确认支付” 处理）；
- 2*MSL 的等待时间，能确保网络中所有 “旧连接的报文” 都已过期（超过 MSL 会被路由器丢弃），此时再用相同四元组建连接，就不会有旧数据干扰。

**通俗类比**：你用同一个手机号给朋友打两次电话（相当于用相同四元组建两次连接）。第一次通话的最后一句 “明天见”（旧报文）因为信号差延迟了 —— 如果你挂了电话立刻重拨，这句 “明天见” 可能会插进新通话里，让朋友误以为是新通话的内容。而等几秒再重拨，旧的 “明天见” 就会消失，新通话不会被干扰。

---



### ③ TCP 协议的三次握手和四次挥手

TCP 的 “三次握手” 和 “四次挥手” 是确保**可靠连接建立**与**安全连接关闭**的核心机制，本质是通过 “报文交互” 确认双方的 “收发能力” 和 “数据传输意愿”。我们可以用 “打电话” 的生活场景类比，让技术逻辑更易理解。

#### 一、TCP 三次握手：建立可靠连接（像 “接通电话前的确认”）

三次握手的目标是：**双方确认 “我能发给你，你也能发给我”**，为后续数据传输铺路。
TCP 连接的发起方称为**客户端（主动打开连接）**，接收方称为**服务器（被动打开连接，先监听端口）**，交互过程如下表：

**Synchronize Sequence Numbers（同步序列号）** 的缩写，是 TCP 三次握手过程中用于**建立连接的关键控制报文**，相当于连接建立时的 “打招呼信号”。

| 步骤 | 发起方 | 发送报文 | 核心作用（通俗解释）                                         | 双方状态变化                                                 |
| ---- | ------ | -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 1    | 客户端 | SYN      | 客户端→服务器：“喂，能听到吗？我想跟你连接”                  | 客户端：`CLOSED` → `SYN_SENT`                                |
| 2    | 服务器 | SYN+ACK  | 服务器→客户端：“能听到！我也能跟你连接，你能听到我吗？”（既回应客户端的 “请求”，也发起自己的 “确认”） | 服务器：`LISTEN` → `SYN_RCVD`                                |
| 3    | 客户端 | ACK      | 客户端→服务器：“能听到你！那我们开始传数据吧”                | 客户端：`SYN_SENT` → `ESTABLISHED`；服务器：`SYN_RCVD` → `ESTABLISHED` |

##### 关键问题：为什么是 “三次”，不是两次或四次？

- **为什么不能是两次？**
  两次握手只能确认 “客户端能发、服务器能收”，但无法确认 “服务器能发、客户端能收”。比如：客户端发的`SYN`报文因网络延迟卡顿，客户端超时重发`SYN`并成功建立连接；后来延迟的`SYN`到达服务器，服务器误以为是新连接，回复`SYN+ACK`但客户端不处理，服务器会一直等待`ACK`，导致资源浪费（“半连接队列” 堆积）。
  **三次握手的第三次`ACK`，能让服务器确认 “客户端已收到我的回应”，避免上述问题。**
- **为什么不用四次？**
  三次握手已足够确认双方收发能力，第四次握手属于 “冗余交互”，会增加连接建立的时间和网络开销，不符合 TCP “高效可靠” 的设计目标。

#### 二、TCP 四次挥手：关闭可靠连接（像 “挂电话前的收尾”）

四次挥手的目标是：**双方确认 “我这边数据已发完，且对方已收到”**，避免数据丢失，安全释放连接资源（端口、内存等）。
连接关闭时，先发起关闭请求的一方称为**主动关闭方**（可能是客户端，也可能是服务器，比如客户端关闭浏览器、服务器主动断开超时连接），另一方称为**被动关闭方**，交互过程如下表：

| 步骤 | 发起方     | 发送报文 | 核心作用（通俗解释）                                         | 双方状态变化                                                 |
| ---- | ---------- | -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 1    | 主动关闭方 | FIN      | 主动方→被动方：“我这边数据发完了，准备关连接”                | 主动方：`ESTABLISHED` → `FIN_WAIT_1`                         |
| 2    | 被动关闭方 | ACK      | 被动方→主动方：“我知道你要关了，我先处理下剩余数据”（仅回应 “收到关闭请求”，不代表自己也准备关） | 被动方：`ESTABLISHED` → `CLOSE_WAIT`；主动方：`FIN_WAIT_1` → `FIN_WAIT_2` |
| 3    | 被动关闭方 | FIN      | 被动方→主动方：“我这边数据也发完了，也准备关”                | 被动方：`CLOSE_WAIT` → `LAST_ACK`                            |
| 4    | 主动关闭方 | ACK      | 主动方→被动方：“我知道你也准备关了，那我等会儿彻底释放”      | 主动方：`FIN_WAIT_2` → `TIME_WAIT`；被动方：`LAST_ACK` → `CLOSED` |

> 注意：主动方发送最后一次`ACK`后，不会立即释放连接，而是进入 **`TIME_WAIT`状态 **（等待 2 倍 MSL，即报文最大生存时间），目的是：① 确保被动方收到最终`ACK`；② 清空网络中残留的 “旧连接报文”，避免干扰新连接（前文已详细解释`TIME_WAIT`）。

##### 关键问题：为什么是 “四次”，不是三次？

核心原因是：**TCP 是 “全双工通信”（双方可同时发数据），关闭连接时需分别确认 “各自的数据流已结束”**。

- 第一次`FIN`：主动方告诉被动方 “我这边不发数据了”；
- 第二次`ACK`：被动方回应 “知道你不发了，但我可能还在发数据，等我发完再告诉你”；
- 第三次`FIN`：被动方发完数据后，告诉主动方 “我这边也不发了”；
- 第四次`ACK`：主动方回应 “知道你也不发了，连接可以关了”。

如果用三次挥手，被动方需在回复`ACK`的同时发送`FIN`，但此时被动方可能还没完成自己的数据传输，会导致数据丢失 —— 因此必须分四次，给双方足够的时间处理剩余数据。

#### 三、三次握手 vs 四次挥手：核心差异总结

| 对比维度     | 三次握手（建立连接）                       | 四次挥手（关闭连接）                                   |
| ------------ | ------------------------------------------ | ------------------------------------------------------ |
| 核心目标     | 确认双方收发能力，建立连接                 | 确认双方数据已传完，释放连接                           |
| 交互次数     | 3 次                                       | 4 次（全双工特性导致需分别关闭）                       |
| 关键报文     | SYN、SYN+ACK、ACK                          | FIN、ACK、FIN、ACK                                     |
| 状态变化重点 | 服务器从`LISTEN`→`SYN_RCVD`→`ESTABLISHED`  | 主动方会进入`TIME_WAIT`，被动方会进入`CLOSE_WAIT`      |
| 失败影响     | 可能导致 “半连接队列” 堆积（SYN 洪水攻击） | 可能导致 “TIME_WAIT 端口耗尽” 或 “CLOSE_WAIT 资源泄漏” |

通过生活类比和步骤拆解，能更清晰地理解：TCP 的 “三次” 和 “四次” 不是随意设计的，而是为了在 “可靠性” 和 “效率” 之间找到平衡 —— 既要确保数据不丢、连接安全，又要避免冗余交互带来的开销。

---



### ③ TCP 的滑动窗口机制

TCP 的滑动窗口机制是实现**流量控制**和**高效数据传输**的核心技术

#### 滑动窗口的核心作用：平衡“发送速度”和“接收能力”

TCP 是 “可靠传输”，但如果发送方一味快速发数据，接收方可能因缓冲区满、处理速度慢而丢包（比如快递点一下子收到 100 个包裹，仓库放不下就会弄丢）。
滑动窗口机制解决的问题：**让发送方根据接收方的 “实际处理能力”，动态调整发送速率**，确保接收方 “能接多少，就发多少”。

> 假设：
>
> - **发送方** = 货车司机（负责运货）
> - **接收方** = 仓库（有固定大小的卸货区，即 “接收缓冲区”）
> - **窗口大小** = 仓库当前能接收的最大货物量（比如仓库还能放 5 箱货，窗口大小就是 5）
>
> #### 1. 窗口大小：接收方告诉发送方 “我还能接多少”
>
> 接收方会在每次回复的`ACK`报文中，附带一个**窗口大小（Window Size）** 字段，告诉发送方：“我现在的缓冲区还能容纳 X 字节的数据，你最多一次发这么多”。
>
> - 比如接收方缓冲区总大小 1000 字节，已用了 300 字节，就会告诉发送方 “窗口大小 = 700 字节”；
> - 如果缓冲区满了（已用 1000 字节），就会告诉发送方 “窗口大小 = 0”，发送方必须暂停发送，直到接收方处理完数据、缓冲区有空闲（窗口大小 > 0）。
>
> #### 2. 发送窗口：发送方 “一次最多能发多少”
>
> 发送方根据接收方的 “窗口大小”，在自己这边维护一个**发送窗口**（想象成一个可滑动的 “许可范围”）：
>
> - 窗口内的数据包：发送方可以 “连续发送”，不用等一个包的`ACK`回来再发下一个（提高效率）；
> - 窗口外的数据包：必须等窗口滑动后才能发送。
>
> 举例：
>
> - 接收方窗口大小 = 3（最多一次接 3 个包）；
> - 发送方先发送 1、2、3 号包（都在窗口内）；
> - 收到接收方回复 “已收到 2 号包，窗口大小还是 3”（`ACK=3`）；
> - 发送窗口向右 “滑动”，此时可以发送 4 号包（窗口内变为 3、4、5 号，其中 3 号已发但未确认，4、5 号可新发送）。
>
> #### 3. 窗口滑动：随确认报文动态调整
>
> 发送窗口的滑动由**接收方的确认报文（ACK）** 触发：
>
> - 当接收方确认收到某个序号的数据包后，发送窗口的 “左边界” 向右移动（释放已确认的数据包资源）；
> - 同时，窗口的 “右边界” 可能随接收方新的窗口大小向左 / 右移动（如果接收方处理快，窗口变大，右边界右移，能发更多数据；如果处理慢，窗口变小，右边界左移，限制发送量）。

#### 滑动窗口的关键优势

1. **提高传输效率**：
   告别 “发一个等一个 ACK” 的低效模式，改为 “一次发窗口内所有包”，尤其在高延迟网络（如跨国通信）中，效率提升明显。
2. **实现流量控制**：
   接收方通过调整窗口大小，直接控制发送方的速率（窗口 = 0 时强制暂停），避免自己被 “数据淹没”。
3. **兼容重传机制**：
   窗口内未被确认的数据包如果超时未收到 ACK，发送方会重传，确保可靠性（比如上述例子中 3 号包丢了，接收方会一直回复`ACK=3`，发送方超时后重传 3 号包）。

滑动窗口就像接收方给发送方的 “动态通行证”—— 通行证上写着 “当前最多能发 X 字节”，发送方只能在这个范围内连续发数据，且随着接收方处理进度 “动态调整通行证权限”，最终实现 “既不丢包，又不浪费带宽” 的高效可靠传输。

> 流量控制就是控制发送方的发送速率，以保证接收方有时间接收。
> TCP 流量控制主要是通过滑动窗口协议实现的。
> 站在发送方的角度，滑动窗口可以分为四个部分：
>
> - **发送并确认**，此部分已经发送，可以忽略;
>
> - **已发送但未确认**，这部分可能在网络中丢失，数据必须保留以便必要时重传；
>
> - **没有发送但可以发送**，这部分接收缓冲区有空间可以保存，可以发送;
>
> - **未发送且暂不可发送**，此部分已超过接收端缓冲区存储空间，即使发送也无意义;
>
>   第2部分和第3部分加起来正好是接收方窗口的大小，它指定当前发送方可以发送的最大数据量。
>
>   在收到确认回复消息之前，发送方必须将发送的报文段保存在窗口中(因为报文段可能在网络中丢失，所以必须将未确认的报文段保存在窗口中，以便在必要时重传)。如果在指定的时间间隔内收到接收方的确认应答报文，这些段将从窗口中清除。
>
> 当发送方收到接收方的确认回复后，清空窗口中的确认消息，窗口向右移动，如下图所示:
>
> ![image-20250910163942064](https://typora-yuanbaoer2.oss-cn-shanghai.aliyuncs.com/img-typora/image-20250910163942064.png)
>
> 随着双方通信的进行，窗口将不断向右移动，因此被形象地称为滑动窗口（Sliding Window）
> 对于 TCP 的接收方，窗口稍微简单点，分为三个部分：
>
> 1. 已接收
> 2. 未接收准备接收 (也即接收窗口，再强调一遍，接收窗口的大小决定发送窗口的大小
> 3. 未接收并未准备接收
>    由于 ACK 直接由 TCP 协议栈回复，默认无应用延迟，不存在 “已接收未回复 ACK”
>
> ![image-20250910164118346](https://typora-yuanbaoer2.oss-cn-shanghai.aliyuncs.com/img-typora/image-20250910164118346.png)

----



### ③ 什么是慢开始门限？

慢开始：如果立即将大量的数据注入到网络中，可能会出现网络的拥塞。因此不要一开始就发送大量的数据，应由小到大逐渐增加拥塞窗口的大小。

---

### ③ synchronized 关键字

Java 中的锁分为显示锁和隐式锁。

隐式锁由 `synchronized` 关键字实现。

显示锁由 `Lock` 接口和 `AQS` 框架等等类来实现。

Java 中的每⼀个对象都可以作为锁，有三种加锁的⽅式：
（1）对于普通同步⽅法，锁是当前实例对象。
（2）对于静态同步⽅法，锁是当前类的 Class 对象
（3）对于同步⽅法块，锁是 Synchonized 括号⾥配置的对象。



---

---

## 第四天 数据库

### ④ 数据库是什么

数据库（Database）是**按照特定结构组织、存储和管理数据的集合**，它能高效地实现数据的存储、查询、更新、共享和保护，是现代信息系统（如网站、APP、企业管理系统等）的核心基础设施。简单来说，数据库就像一个 “智能化的电子文件柜”，但比传统文件柜更灵活、更高效 —— 它能按规则自动分类数据，支持快速检索，并确保多用户同时使用时的数据准确性。

---

### ④ 数据库有哪几种类型

数据库的类型划分核心是**数据模型**（即数据的组织、存储和查询方式），不同类型对应不同的业务场景需求。

- **关系型数据库**：核心是以**表格**形式存储数据

  - **核心特点**

    - **结构化存储**：数据需提前定义 “表结构”（如字段名、数据类型），格式固定，适合存储有明确规则的数据（如用户信息、订单详情）；
    - **ACID 特性**：严格遵循事务的 ACID 原则（原子性 Atomic、一致性 consistence、隔离性、持久性），确保数据操作的完整性（如转账时 “扣款” 和 “到账” 必须同时成功或失败）；
    - **支持 SQL**：通过标准化的 SQL 语言（结构化查询语言）实现数据查询、插入、修改，学习和使用门槛低。

    **代表产品**

    - MySQL：开源免费，轻量高效，广泛用于互联网场景（如网站后台、APP 用户系统）；
    - Oracle：企业级商业数据库，性能强、安全性高，常用于金融（银行核心系统）、电信等关键业务；
    - SQL Server：微软生态产品，与 Windows、Office 等工具兼容性好，适合企业内部管理系统（如 ERP、CRM）；
    - PostgreSQL：开源且功能全面，支持复杂数据类型（如地理信息、JSON），适合需要定制化的场景。

- **非关系型数据库（NoSQL）**：Not Only SQL，

  | 细分类型         | 核心逻辑                                                     | 特点                                                         | 代表产品           | 应用场景                                                     |
  | ---------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------ | ------------------------------------------------------------ |
  | **键值型数据库** | 以 “键（Key）= 值（Value）” 形式存储，Value 可是字符串、JSON 等 | 查询速度极快（O (1) 复杂度），适合简单数据存储               | Redis、Memcached   | 缓存（如电商首页商品缓存）、会话存储（用户登录状态）、计数器（点赞数、阅读量） |
  | **文档型数据库** | 以 “文档” 为单位存储（如 JSON、XML），文档内字段可灵活定义   | 无需预定义表结构，支持复杂查询，适合半结构化数据             | MongoDB、CouchDB   | 社交平台用户动态（如朋友圈、微博）、博客内容、电商商品详情（属性多变的商品） |
  | **列族型数据库** | 按 “列族”（Column Family）分组存储，列族内包含多个列，适合分布式存储 | 高写入性能，支持海量数据（PB 级），按列查询高效              | HBase、Cassandra   | 大数据日志分析（如服务器访问日志）、物联网设备数据存储、金融交易流水 |
  | **图数据库**     | 以 “节点（Node）” 和 “边（Edge）” 存储数据，专注于数据间的关联关系 | 高效查询复杂的关联网络（如 “朋友的朋友”），避免多表关联的性能损耗 | Neo4j、NebulaGraph | 社交网络关系分析（如推荐 “可能认识的人”）、知识图谱（如百度百科关联词条）、欺诈检测（金融风控） |

- **时序数据库**：专门针对**带时间戳的数据**（如实时监控数据、传感器数据），核心优化了“时间维度”，能高效处理 “高写入、高查询、按时间范围分析” 的场景。

  **核心特点**

  - **时间有序存储**：数据以时间戳为核心索引，默认按时间顺序排列，适合追溯历史数据；
  - **高写入性能**：针对 “高频、连续” 的数据写入优化（如每秒 thousands 级别的数据写入）；
  - **自动压缩与生命周期管理**：可自动压缩历史数据（如按小时 / 天聚合），并设置数据过期策略（如保留 3 个月数据），节省存储成本；
  - **时间范围查询高效**：快速响应 “查询某设备过去 24 小时的温度变化”“查询上周服务器 CPU 峰值” 等时间维度查询。

  #### 代表产品

  - InfluxDB：开源时序数据库，常用于物联网监控、应用性能监控（APM）；
  - Prometheus：与 Grafana 搭配使用，广泛用于服务器、容器（如 K8s）的性能监控；
  - TDengine：国产开源时序数据库，针对物联网场景优化，支持边缘端与云端协同。

---

### ④ 第三范式（3NF）与第二范式的区别是什么

在第二范式的基础上，非主键列只直接依赖于主键，不依赖于其他非主键。

更多后端面试考点，可学习[数据库知识手册](https://leetcode.cn/leetbook/detail/database-handbook/)





---

### ④ 触发器的使用场景有哪些

- 需要通过数据库中的相关表实现级联更改
- 需要实时监控某张表中的某个字段的更改情况，并需要做出相应的处理。



---

### ④ 数据库索引根据结构分为哪几类

三类

- B树索引（B+树是在B树的基础上的一种优化，更适合实现外存储索引结构）
- 哈希索引
- 位图索引



### ④ B+ 树与B树的区别

由于 B+ 树的内部结点（非叶子结点）只存放键，不存放值，因此，一次读取，可以在同一内存页中获取更多的键，有利于更快地缩小查找范围。

B+ 树的叶结点由一条链（双向链表）相连，因此当需要进行一次 全数据遍历 的时候，B+ 树只需要使用 O(logN) 时间找到最小结点，然后通过链进行 O(N) 的顺序遍历即可；或者，在找 大于某个关键字或者小于某个关键字的数据 的时候，B+ 树只需要找到该关键字然后沿着链表遍历即可。



---

### ④ Hash 索引和 B+ 树索引哪个不支持模糊查询以及多列索引的最左前缀匹配？为什么？必须回表查

Hash 索引和 B+ 树索引有以下几点显见的区别：

- Hash 索引进行等值查询更快（一般情况下），但是却无法进行范围查询；
- Hash 索引不支持使用索引进行排序；
- Hash 索引不支持模糊查询以及多列索引的最左前缀匹配，原理也是因为 Hash 函数的不可预测；
- Hash 索引任何时候都避免不了回表查询数据，而 B+ 树在符合某些条件（聚簇索引，覆盖索引等）的时候可以只通过索引完成查询；
- Hash 索引虽然在等值查询上较快，但是不稳定，性能不可预测，当某个键值存在大量重复的时候，发生 Hash 碰撞，此时效率可能极差；而 B+ 树的查询效率比较稳定，对于所有的查询都是从根结点到叶子结点，且树的高度较低。



---

### ④ 添加索引时需要注意哪些原则？

- 在查询中很少使用，或进行参考的列，不要对其创建索引
- 只有很少数据值的列也不应该添加索引
- 定义为 text、image和bit数据类型的列不应该添加索引
- 当修改性能远远大于检索性能时，不应该创建索引
- 定义有外键的数据列一定要创建索引

---

### ④ 什么是数据库事务

数据库的 事务（Transaction）是一种机制、一个操作序列，包含了一组数据库操作命令，**其执行的结果必须使数据库从一种一致性状态变到另一种一致性状态**。事务把所有的命令作为一个整体一起向系统提交或撤销操作请求，**即这一组数据库命令要么都执行，要么都不执行**，因此事务是一个不可分割的工作逻辑单元。如果任意一个操作失败，那么整组操作即为失败，会回到操作前状态或者是上一个节点。

因此，事务是保持 **逻辑数据一致性** 和 **可恢复性** 的重要利器。而锁是实现事务的关键，可以保证事务的完整性和并发性。



---

### ④ 事务的四个特性 ACID

- 原子性 Atomicity
- 一致性 Consistency
- 隔离性 Isolation
- 持久性 Durability
